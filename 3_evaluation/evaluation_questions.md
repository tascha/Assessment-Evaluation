## Evaluation questions {#evaluation-questions}

You probably have some idea of _why_ you are conducting an evaluation—possibly one of the reasons listed in [_What is an evaluation?_](../1_introduction/what_is_an_evaluation.md) For instance, evaluations can directly affect future actions or decisions or change someone’s attitude or way of thinking.<sup><sup id="174453654767466-footnote-ref-9"><a href="#174453654767466-footnote-9">[9]</a></sup></sup> Evaluation questions transform a vague idea into specific elements that are tied to one or more outcomes and can be measured through assessments.

All evaluations answer the same three fundamental questions, according to the [**_Principal Investigator’s Guide_**](http://www.informalscience.org/evaluation/pi-guide):<sup><sup id="174453654767466-footnote-ref-10"><a href="#174453654767466-footnote-10">[10]</a></sup></sup>

1.  What? (What happened or happens and what are the results?)
2.  So what? (Why did the results occur the way they did, and what are the implications?)
3.  Now what? (What actions, decisions, or recommendations can be made based on the results?)

### Evaluation question do’s and don’ts {#evaluation-question-do-s-and-don-ts}

| **DON’T** | **DO** |
| --- | --- |
| Ask more questions than you have time or resources to answer | Prioritize questions based on the value of their answers and your ability to answer them<sup><sup id="174453654767466-footnote-ref-11"><a href="#174453654767466-footnote-11">[11]</a></sup></sup> |
| Come up with all the questions yourself | Talk to stakeholders for their input |
| Try to answer all questions from every stakeholder | Use stakeholder input to _inform_ the evaluation design, not _determine_ it |
| Ask questions that are too broad or aspirational | Ask questions that can be answered realistically |

**EVALUATION QUESTION EXAMPLES**

_How financially sustainable is the robotics lab?_

_Does the robotics lab help teens develop collaboration skills?_

### Types of evaluations {#types-of-evaluations}

| **EVALUATION TYPE** | **DESCRIPTION** | **EXAMPLES** |
| --- | --- | --- |
| Front-end evaluation | Used in informal science education; similar to audience or user research and used to inform the initial design of a program.<sup><sup id="174453654767466-footnote-ref-12"><a href="#174453654767466-footnote-12">[12]</a></sup></sup> | What aspects of this topic are our youth interested in? |
| Formative evaluation | Periodic evaluations conducted during the development and implementation of a program. Used for course-correcting if necessary. Formative evaluation can look at how a project is progressing towards its goals whether the implementation of the project going according to plan.<sup><sup id="174453654767466-footnote-ref-13"><a href="#174453654767466-footnote-13">[13]</a></sup></sup> | Are participants learning what we expected? |
| Summative evaluation | Focuses on conditions at the end of the program and is an evaluation of the entire process. It may report results from earlier formative evaluations as well. | Did participants learn what and as much as we wanted? |

[^9]: http://search.credoreference.com/content/entry/sageeval/evaluation_use/

[^10]: Bonney, R., Ellenbogen, K., Goodyear, L., &amp; Hellenga, R. (Eds.). (2001). _Principal investigator’s guide: Managing evaluation in informal STEM education projects_. Washington, D.C.: Center for Advancement of Informal Science Education. Retrieved from

[^11]: PI Guide pg. 51

[^12]: Bonney, R., Ellenbogen, K., Goodyear, L., &amp; Hellenga, R. (Eds.). (2001). _Principal investigator’s guide: Managing evaluation in informal STEM education projects_. Washington, D.C.: Center for Advancement of Informal Science Education. Retrieved from

[^13]: Westat, J. F. (2010). _The 2010 user-friendly handbook for project evaluation_. Washington, D.C.: National Science Foundation. Retrieved from