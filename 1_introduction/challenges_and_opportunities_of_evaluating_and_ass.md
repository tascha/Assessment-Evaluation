## Challenges and opportunities of evaluating and assessing connected learning {#challenges-and-opportunities-of-evaluating-and-assessing-connected-learning}

Some of the approaches used for measuring learning in a traditional classroom can be difficult or impossible to apply in connected learning settings. For example,

*   Without mandatory assessments that are possible in formal learning settings, collecting information about individual learners can be more difficult
*   While teachers can assess a student throughout a school year, before-and-after or longitudinal assessment of individuals can be virtually impossible—especially with drop-in experiences<sup><sup id="174453654767466-footnote-ref-2"><a href="#174453654767466-footnote-2">[2]</a></sup></sup>
*   Rigorous experimental designs are difficult because learners’ motivations, prior knowledge, and experiences can vary even more than they do in schools where students are grouped by age
*   Connected learning encompasses a broader definition of “learning,” and there may not be an existing instrument that can assess the impact of the learning experiences that you are providing to your teens
*   By definition, connected learning occurs across multiple contexts, not just at the library

**PROGRAM EVALUATIONS FOR CONNECTED LEARNING**

[embed video: https://youtu.be/u6rguxNk8kY]

In this [short trailer](https://youtu.be/u6rguxNk8kY) for his free online [_Program Evaluations for Connected Learning_](https://dmlcommons.net/2016-course/)course, Dr. William Penuel from the University of Colorado at Boulder describes the class as well as some of the challenges and opportunities of evaluating connected learning programs.

These challenges are not insurmountable! They’re just unfamiliar—for now. Fortunately, connected learning initiatives also present opportunities to be creative and flexible in the ways you evaluate and assess them. Your approach can be tailored for your library’s unique situation and context. Some of these opportunities include:

*   You have the ability to conduct assessments that are shorter, more flexible, and on-the-fly
*   Assessments don’t have to be broad and all-encompassing; you can assess the impact or value of single visits to the library
*   Assessing connected learning can be an excellent opportunity to learn about the social aspects of learning and group dynamics of your youth
*   An evaluation can highlight an initiative’s value to a wide range of people, not just the immediate participants
*   Creating your own instrument can help you evaluate the unique characteristics of your program
*   Participants are more likely to give authentic feedback when they feel like they are being listened to, not tested
*   You can learn how your library impacts the other “connected” aspects of participants’ lives

By the end of this module, you will feel confident about evaluating and assessing connected learning and connected learning initiatives at your library.

**ADDITIONAL RESOURCES**

*   The [**Community Toolbox**](http://ctb.ku.edu/en/table-of-contents) provides a detailed [**Introduction to Evaluation**](http://ctb.ku.edu/en/table-of-contents/evaluate/evaluation) from a community development perspective.
*   For a deeper dive into evaluating connected learning programs, [**Program Evaluations for Connected Learning**](https://dmlcommons.net/2016-course/)(William Penuel &amp; Carrie Allen, 2016) is a free online course consisting of eight modules covering topics like &quot;measuring and using implementation evidence&quot; and “developing a theory of change to guide evaluation.”
*   [**BetterEvaluation**](http://www.betterevaluation.org/)is an extensive collection of information for every stage and aspect of evaluation.
*   IMLS (2015) has collected a list of [**Evaluation Resources**](https://www.imls.gov/research-evaluation/evaluation-resources) from a variety of sources.

**Evaluating and Assessing Informal Learning**

*   See Chapter 6 of [**Surrounded by Science**](http://www.nap.edu/catalog/12614)(Marilyn Fenichel &amp; Heidi A. Schweingruber, 2010) for a discussion of “Assessing Learning Outcomes.”
*   The [**Principal Investigator’s Guide: Managing Evaluation in Informal STEM Education Projects**](http://www.informalscience.org/evaluation/pi-guide)(CAISE, 2011) was written for NSF-funded projects, but it contains extensive advice and examples that are useful for any informal learning context.
*   Chapter 5 of **_Putting Teens First in Library Services: A Roadmap_**, (Linda Braun &amp; Shannon Peterson, eds., 2017), discusses “Assessments and Outcome-Based Evaluation in Formal and Informal Learning Spaces.” (Chicago, IL: YALSA).
*   Chapters 5 through 10 of [**Framework for Evaluating Impacts of Informal Science Education Projects**](http://www.informalscience.org/framework-evaluating-impacts-informal-science-education-projects), edited by Alan J. Friedman for the National Science Foundation, discuss the challenges of evaluating particular types of informal learning experiences like exhibits or media productions.
*   [**InformalScience.org**](http://www.informalscience.org/evaluation)has a set of evaluation resources specifically designed for informal STEM learning.

[^2]: